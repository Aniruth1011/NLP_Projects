{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "8988d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r\"tam.txt\"\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense \n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "0c88dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c496b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8c0ed85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ca75a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_characters = sorted(list(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "3d648a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=target_texts\n",
    "target_texts=input_texts\n",
    "input_texts=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d84c81f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8ac419f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "f1e44853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "a0dccf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer(filters='') \n",
    "tokenizer_outputs = Tokenizer(filters='')\n",
    "tokenizer_inputs.fit_on_texts(input_texts) \n",
    "tokenizer_outputs.fit_on_texts(target_texts)\n",
    "input_texts = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "output_sequences = tokenizer_outputs.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "8f144d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size\n",
    "input_vocab_size = len(tokenizer_inputs.word_index) \n",
    "output_vocab_size = len(tokenizer_outputs.word_index) \n",
    "\n",
    "# Padding sequences\n",
    "max_input_length = max(len(seq) for seq in input_texts) + 1\n",
    "max_output_length = max(len(seq) for seq in output_sequences) + 1 \n",
    "\n",
    "padded_input_sequences = pad_sequences(input_texts, maxlen=20, padding='post')\n",
    "padded_output_sequences = pad_sequences(output_sequences, maxlen=20, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "a6f15df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "77024b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 20)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "cf2a4d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "a4931192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d591ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "47ab6a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 20)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "d65159be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "895cc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "28bb5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(20,))\n",
    "encoder_embedding = Embedding(input_vocab_size + 1, embedding_dim)(encoder_inputs)  # Add 1 to vocab size\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length,))\n",
    "decoder_embedding = Embedding(output_vocab_size + 1, embedding_dim)(decoder_inputs)  # Add 1 to vocab size\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size + 1, activation='softmax')  # Add 1 to vocab size\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "9ddafae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "model.compile(optimizer= Adam(), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "676e56e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 20)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "9b1b74a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 20ms/step - loss: 6.0372\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.5933\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.0919\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.8789\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.6296\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5800\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.5486\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.5269\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.5135\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5021\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4917\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4822\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4738\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4638\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.4542\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4463\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4382\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4290\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4198\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4107\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4010\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.4244\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4126\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4034\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.3937\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.3837\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3767\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.3635\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.3534\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.3348\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3129\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.3025\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2909\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.2833\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 1.2756\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2673\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2608\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2525\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2484\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.2392\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.2316\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.2254\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.2177\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.2106\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2039\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.1955\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 1.1878\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.1796\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.1715\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1641\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1569\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1490\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.1414\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1337\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1264\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1185\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.1102\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.1033\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0953\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0876\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0802\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0736\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0656\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0582\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0508\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0439\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0365\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0297\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0225\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0158\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0077\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0007\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9937\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9869\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9794\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9725\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9653\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9577\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9509\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9432\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9361\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9294\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9219\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9154\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9092\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9037\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8955\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8869\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8793\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8721\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8648\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8579\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8497\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8432\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8360\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8283\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8202\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8131\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8084\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15888053910>"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([padded_input_sequences, padded_output_sequences], padded_output_sequences, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "5612b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[\"நான் மிகவும் சந்த ாஷமாக இருக்கிதேன\",\"அது அவசியமில்லை\",\" யவுசசய்து அல மீண்டும் சசய்யவும\",\"அது ஒரு நல்ை தயாசலை\",\"அவர்கள் ஒன்ோக தவலை சசய்ய ஒப்புக்சகாண்டைர\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "ebb85307",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=[\"Im so happy\",\"It wasnt necessary\",\"Please do that again\",\"That is good idea\",\"They agreed to work together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "738e0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenize test input and output texts\n",
    "test_input_sequences = tokenizer_inputs.texts_to_sequences(x_test)\n",
    "test_output_sequences = tokenizer_outputs.texts_to_sequences(y_test)\n",
    "\n",
    "# Padding test sequences\n",
    "padded_test_input_sequences = pad_sequences(test_input_sequences, maxlen=20, padding='post')\n",
    "padded_test_output_sequences = pad_sequences(test_output_sequences, maxlen=20, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "ee9c12d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_test_output_sequences.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "71551047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 20, 432), dtype=float32, numpy=\n",
       "array([[[7.18859141e-04, 1.72264234e-03, 4.21835482e-03, ...,\n",
       "         6.12144220e-07, 3.92523407e-06, 7.59035970e-07],\n",
       "        [3.99596378e-04, 1.63226649e-02, 2.14929450e-02, ...,\n",
       "         3.71074589e-06, 1.10515939e-05, 2.76526839e-06],\n",
       "        [1.36367627e-03, 1.34672463e-01, 1.13332592e-01, ...,\n",
       "         6.48132618e-06, 1.25808047e-05, 4.27751866e-06],\n",
       "        ...,\n",
       "        [9.98113990e-01, 1.08783424e-04, 1.98772468e-05, ...,\n",
       "         9.15788405e-06, 6.19630964e-06, 1.90259525e-05],\n",
       "        [9.98113990e-01, 1.08777298e-04, 1.98764319e-05, ...,\n",
       "         9.15775308e-06, 6.19621505e-06, 1.90257706e-05],\n",
       "        [9.98113990e-01, 1.08773667e-04, 1.98759608e-05, ...,\n",
       "         9.15767396e-06, 6.19615003e-06, 1.90256615e-05]],\n",
       "\n",
       "       [[7.70295039e-04, 6.90793153e-04, 2.10792175e-03, ...,\n",
       "         7.22310631e-07, 6.48884770e-06, 1.15483044e-06],\n",
       "        [3.72880808e-04, 9.69298091e-03, 1.47818560e-02, ...,\n",
       "         2.80859877e-06, 1.35918326e-05, 2.68079930e-06],\n",
       "        [1.21492916e-03, 7.47445151e-02, 6.83618709e-02, ...,\n",
       "         6.21061463e-06, 1.34358343e-05, 4.21496316e-06],\n",
       "        ...,\n",
       "        [9.98113990e-01, 1.08786015e-04, 1.98775524e-05, ...,\n",
       "         9.15784949e-06, 6.19632146e-06, 1.90258797e-05],\n",
       "        [9.98113990e-01, 1.08778651e-04, 1.98765847e-05, ...,\n",
       "         9.15771761e-06, 6.19620914e-06, 1.90256978e-05],\n",
       "        [9.98113990e-01, 1.08774082e-04, 1.98759790e-05, ...,\n",
       "         9.15763030e-06, 6.19613229e-06, 1.90255523e-05]],\n",
       "\n",
       "       [[7.70295039e-04, 6.90793153e-04, 2.10792175e-03, ...,\n",
       "         7.22310631e-07, 6.48884770e-06, 1.15483044e-06],\n",
       "        [3.72880808e-04, 9.69298091e-03, 1.47818560e-02, ...,\n",
       "         2.80859877e-06, 1.35918326e-05, 2.68079930e-06],\n",
       "        [1.21492916e-03, 7.47445151e-02, 6.83618709e-02, ...,\n",
       "         6.21061463e-06, 1.34358343e-05, 4.21496316e-06],\n",
       "        ...,\n",
       "        [9.98113990e-01, 1.08786015e-04, 1.98775524e-05, ...,\n",
       "         9.15784949e-06, 6.19632146e-06, 1.90258797e-05],\n",
       "        [9.98113990e-01, 1.08778651e-04, 1.98765847e-05, ...,\n",
       "         9.15771761e-06, 6.19620914e-06, 1.90256978e-05],\n",
       "        [9.98113990e-01, 1.08774082e-04, 1.98759790e-05, ...,\n",
       "         9.15763030e-06, 6.19613229e-06, 1.90255523e-05]],\n",
       "\n",
       "       [[8.31942423e-04, 2.29659420e-03, 1.47116114e-03, ...,\n",
       "         1.20914706e-07, 1.35970436e-06, 1.71976609e-07],\n",
       "        [4.58230061e-04, 8.85720365e-03, 8.56363028e-03, ...,\n",
       "         2.99408498e-06, 1.53787041e-05, 2.70929627e-06],\n",
       "        [1.07690063e-03, 7.44367912e-02, 5.11496216e-02, ...,\n",
       "         6.01831562e-06, 1.55614343e-05, 4.02601245e-06],\n",
       "        ...,\n",
       "        [9.98113990e-01, 1.08789020e-04, 1.98777798e-05, ...,\n",
       "         9.15798864e-06, 6.19638058e-06, 1.90261344e-05],\n",
       "        [9.98113990e-01, 1.08780107e-04, 1.98766411e-05, ...,\n",
       "         9.15776127e-06, 6.19622097e-06, 1.90257342e-05],\n",
       "        [9.98113990e-01, 1.08775021e-04, 1.98760354e-05, ...,\n",
       "         9.15764849e-06, 6.19613820e-06, 1.90255705e-05]],\n",
       "\n",
       "       [[7.70295039e-04, 6.90793153e-04, 2.10792175e-03, ...,\n",
       "         7.22310631e-07, 6.48884770e-06, 1.15483044e-06],\n",
       "        [3.72880808e-04, 9.69298091e-03, 1.47818560e-02, ...,\n",
       "         2.80859877e-06, 1.35918326e-05, 2.68079930e-06],\n",
       "        [1.21492916e-03, 7.47445151e-02, 6.83618709e-02, ...,\n",
       "         6.21061463e-06, 1.34358343e-05, 4.21496316e-06],\n",
       "        ...,\n",
       "        [9.98113990e-01, 1.08786015e-04, 1.98775524e-05, ...,\n",
       "         9.15784949e-06, 6.19632146e-06, 1.90258797e-05],\n",
       "        [9.98113990e-01, 1.08778651e-04, 1.98765847e-05, ...,\n",
       "         9.15771761e-06, 6.19620914e-06, 1.90256978e-05],\n",
       "        [9.98113990e-01, 1.08774082e-04, 1.98759790e-05, ...,\n",
       "         9.15763030e-06, 6.19613229e-06, 1.90255523e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([padded_test_input_sequences ,padded_test_input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fda02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
